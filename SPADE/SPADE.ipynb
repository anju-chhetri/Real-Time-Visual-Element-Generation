{"cells":[{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":542,"status":"ok","timestamp":1679830887610,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"dm-Bzrjon1rt"},"outputs":[],"source":["import zipfile\n","import os\n","# !unzip /content/drive/MyDrive/grass/datasets/train.zip -d /content/train\n","# with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/train_channel7.zip\",\"r\") as zf:\n","#     zf.extractall(\"/content/train/\")\n","\n","# if not os.path.exists(\"/content/train/generated/\"):\n","#     os.makedirs(\"/content/train/generated/\")\n","\n","# with zipfile.ZipFile(\"/content/drive/MyDrive/Colab Notebooks/grass_style_transfer_references.zip\",\"r\") as zf2:\n","#     zf2.extractall(\"/content/train/refs/\")"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":935,"status":"ok","timestamp":1679830889151,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"AKPXPP5kUvZH"},"outputs":[],"source":["config_defaults = {\n","    'BATCH_SIZE' : 8,\n","    'IN_CHANNEL_GEN' : 7,\n","    'IN_CHANNEL_DIS' : 10,\n","\n","    'OUT_CHANNEL' : 3,\n","    'PATH_DATA' : '/content/train/',\n","    'PATH' : '/content/drive/MyDrive/Colab Notebooks/seashell 14 results/lightning_logs/version_4/checkpoints/epoch=27-step=14000.ckpt',\n","    'MAX_EPOCH' : 10,\n","    'Lr_GEN' : 0.001,\n","    'Lr_DIS' : 0.004,\n","    'RESULT_PATH': '/content/drive/MyDrive/grass/experiments/example-sea-creature-30050/',\n","    }\n","CONFIG = config_defaults"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1679830889153,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"K4uCq9_nUslg"},"outputs":[],"source":["#Downloading data from kaggle\n","from torch.utils.data import DataLoader, Dataset\n","import pandas as pd\n","from torchvision import transforms\n","from PIL import Image\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","plt.rcParams['figure.figsize'] = (20, 12)\n","\n","import sys\n","from torch.nn import Module, Conv2d\n","from torch.nn.utils import spectral_norm\n","from torch.nn.functional import interpolate, relu\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from torch.nn.functional import leaky_relu\n","from torch.nn.utils import spectral_norm\n","\n","\n","# if not os.path.isdir(CONFIG['PATH_DATA']):\n","#   !pip install -q kaggle\n","#   !mkdir ~/.kaggle\n","#   !pwd\n","#   from google.colab import files\n","#   files.upload()\n","#   !cp kaggle.json ~/.kaggle/\n","#   !chmod 600 ~/.kaggle/kaggle.json\n","#   #!kaggle datasets list\n","#   !kaggle datasets download -d fluxo4/grass-generation-training-set -p /content/\n","#   !unzip /content/grass-generation-training-set.zip -d /content/drive/MyDrive/grass-generation-training-set\n"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1679830889155,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"GZrmaJ11m4RO"},"outputs":[],"source":["class GrassDataset(Dataset):\n","  def __init__(self, path, num_items = -1):\n","    self.df = pd.read_csv(path + \"train.csv\")\n","    self.path = path\n","    self.length = num_items\n","    if num_items == -1:\n","      self.length = len(self.df)\n","    else:\n","      self.length = min(len(self.df),num_items)\n","      self.df = self.df.sample(n = self.length, replace=False)\n","    self.df = self.df.reset_index(drop=True)\n","    self.df.head()\n","\n","  def __len__(self):\n","    return self.length\n","\n","  def __getitem__(self, idx):\n","    inputImagePath = self.path + self.df['Input'][idx][2:]\n","       \n","    inputImage = Image.open(inputImagePath)\n","    inputImage = transforms.functional.to_tensor(inputImage)\n","\n","   \n","    depthImagePath = self.path + self.df['Depth'][idx][2:]\n","    depthImage = Image.open(depthImagePath)\n","    depthImage = transforms.functional.to_tensor(depthImage)\n","\n","    nImagePath = self.path + self.df['Normal'][idx][2:]\n","    nImage = Image.open(nImagePath)\n","    nImage = transforms.functional.to_tensor(nImage)\n","\n","    realImagePath = self.path + self.df['Output'][idx][2:]\n","    realImage = Image.open(realImagePath)\n","    real = transforms.functional.to_tensor(realImage)\n","   \n","    #                                       here\n","    condition = torch.cat((inputImage, depthImage[0:1, :, :], nImage), 0) # (3+1+3 = 7) x 480 x 800\n","\n","    return condition, real\n","\n","class RAMGrassDataset(Dataset): \n","#This one loads the dataset onto the RAM, to speed up training speed, especially if you're running a large number of epochs\n","#Be very careful about how many items you want there to be here\n","  def __init__(self, path, num_items = -1):\n","    print(\"preparing RAM dataset, hopefully this doesn't take very long\")\n","    self.df = pd.read_csv(path + \"train.csv\")\n","    self.path = path\n","    self.length = num_items\n","    if num_items == -1:\n","      self.length = len(self.df)\n","    else:\n","      self.length = min(len(self.df),num_items)\n","      self.df = self.df.sample(n = self.length, replace=False)\n","    self.df = self.df.reset_index(drop=True)\n","\n","\n","    self.real = []\n","    self.condition = []\n","    print(\"prepared all variables, adding data to RAM\")\n","    for i in range(self.length):\n","      idx, real, condition = self.getitem(i)\n","      self.real.append(real)\n","      self.condition.append(condition)\n","    print(\"dataset added to RAM\")\n","\n","  def __len__(self):\n","    return self.length\n","\n","  def __getitem__(self, idx):\n","    return self.real[idx], self.condition[idx]\n","\n","  def getitem(self, idx):\n","    inputImagePath = self.path + self.df['Input'][idx][2:]\n","       \n","    inputImage = Image.open(inputImagePath)\n","    inputImage = transforms.functional.to_tensor(inputImage)\n","\n","    print(inputImage)\n","    depthImagePath = self.path + self.df['Depth'][idx][2:]\n","    depthImage = Image.open(depthImagePath)\n","    depthImage = transforms.functional.to_tensor(depthImage)\n","\n","    nImagePath = self.path + self.df['Normal'][idx][2:]\n","    nImage = Image.open(nImagePath)\n","    nImage = transforms.functional.to_tensor(nImage)\n","\n","\n","    realImagePath = self.path + self.df['Output'][idx][2:]\n","    realImage = Image.open(realImagePath)\n","    real = transforms.functional.to_tensor(realImage)\n","\n","    #                                       here\n","    condition = torch.cat((inputImage, depthImage[0:1, :, :], nImage), 0) # (3+1+3 = 7) x 480 x 800\n","\n","    return  condition,real\n"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1679830889156,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"R11uZ91Sn34T"},"outputs":[],"source":["class Args:\n","    def __init__(self, spade_filter=128, spade_kernel=3, spade_resblk_kernel=3, gen_input_size=256, gen_hidden_size=16384):\n","        self.spade_filter = spade_filter\n","        self.spade_kernel = spade_kernel\n","        self.spade_resblk_kernel = spade_resblk_kernel\n","        self.gen_input_size = gen_input_size\n","        self.gen_hidden_size = gen_hidden_size\n","        \n","        if gen_hidden_size%16 != 0:\n","            print(\"Gen hidden size not multiple of 16\")\n","\n","spade_filter = 64\n","gen_input_size = 256\n","gen_hidden_size = 128 * 375\n","args = Args(spade_filter, 3, 3, gen_input_size, gen_hidden_size)\n","\n","\n","# def weights_init(m):\n","#     classname = m.__class__.__name__\n","#     if classname.find('Conv') != -1:\n","#         nn.init.normal_(m.weight.data, 0.0, 0.02)\n","#     elif classname.find('BatchNorm') != -1:\n","#         nn.init.normal_(m.weight.data, 1.0, 0.02)\n","#         nn.init.constant_(m.bias.data, 0)\n","\n","def weights_init(m):\n","    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","    if isinstance(m, nn.BatchNorm2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","        torch.nn.init.constant_(m.bias, 0)\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1679830889157,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"k3Mikz6in6PS"},"outputs":[],"source":["from pandas._libs.lib import fast_unique_multiple_list_gen\n","\n","\n","inchannel = 7\n","class SPADE(Module):\n","    def __init__(self, args, k):\n","        super().__init__()\n","        num_filters = args.spade_filter\n","        kernel_size = args.spade_kernel\n","        self.conv = spectral_norm(Conv2d(inchannel, num_filters, kernel_size=(kernel_size, kernel_size), padding=1)) #made changes on inputChannel\n","        self.conv_gamma = spectral_norm(Conv2d(num_filters, k, kernel_size=(kernel_size, kernel_size), padding=1))\n","        self.conv_beta = spectral_norm(Conv2d(num_filters, k, kernel_size=(kernel_size, kernel_size), padding=1))\n","\n","\n","    def forward(self, x, seg):\n","        #x = (b, 128, h, w), seg = (b, 4, h,w )\n","        # print('In SPADE')\n","        # seg_copy = self.convseg(seg) #seg = (b, 128, h,w)\n","        N, C, H, W = x.size()\n","        sum_channel = torch.sum(x.reshape(N, C, H*W), dim=-1)\n","\n","        mean = sum_channel / (N*H*W)\n","\n","        std = torch.sqrt((sum_channel**2 - mean**2) / (N*H*W))\n","        mean = torch.unsqueeze(torch.unsqueeze(mean, -1), -1)\n","        std = torch.unsqueeze(torch.unsqueeze(std, -1), -1)\n","        x = (x - mean) / std\n","\n","        # seg = interpolate(seg, size=(H,W), mode='nearest')\n","        seg_copy = relu(self.conv(seg))  #------------------------------->CPU and !CUDA\n","        # print(f'seg_copy: {seg_copy.shape}')\n","\n","        seg_gamma = self.conv_gamma(seg_copy)\n","        # print(f'seg_gamma: {seg_gamma.shape}')\n","\n","        seg_beta = self.conv_beta(seg_copy)\n","        # print(f'seg_beta: {seg_beta.shape}')\n","\n","        #torch.matmul performs matrix multiplication so for the given equal sized vectors need to make size of seg_gamma such that seg_gamma.size(3)=x.size(2)\n","        #so taking the difference between those two those indices concatinating the difference to x\n","        x_copy = torch.cat((x, torch.zeros(x.size(0), x.size(1), seg_gamma.size(3)-x.size(2), x.size(3)).to(device)), dim = 2)\n","        # print(f'x_copy: {x_copy.shape}')\n","\n","        x = (torch.matmul(seg_gamma, x_copy) + seg_beta)\n","        # print(f'exit: {x.shape}')\n","        return x\n","\n","\n","class SPADEResBlk(Module):\n","    def __init__(self, args, k, skip=False):\n","        super().__init__()\n","        kernel_size = args.spade_resblk_kernel\n","        self.skip = skip\n","        \n","        if self.skip:\n","            self.spade1 = SPADE(args, 2*k)\n","            self.conv1 = Conv2d(2*k, k, kernel_size=(kernel_size, kernel_size), padding=1, bias=False)\n","            self.spade_skip = SPADE(args, 2*k)\n","            self.conv_skip = Conv2d(2*k, k, kernel_size=(kernel_size, kernel_size), padding=1, bias=False)\n","        else:\n","            self.spade1 = SPADE(args, k)\n","            self.conv1 = Conv2d(k, k, kernel_size=(kernel_size, kernel_size), padding=1, bias=False)\n","\n","        self.spade2 = SPADE(args, k)\n","        self.conv2 = Conv2d(k, k, kernel_size=(kernel_size, kernel_size), padding=1, bias=False)\n","    \n","    def forward(self, x, seg):\n","        # print(f'In SpadeResBlk')\n","        x_skip = x\n","        # print(f'before spade1: x {x.shape} seg: {seg.shape} ')\n","        x = relu(self.spade1(x, seg)) #b, 128, 30, 50\n","        # print(f'x: {x.shape}')\n","        # print(f'After spade1: {x.shape}')\n","        x = self.conv1(x) #b, 128, 30, 50\n","\n","        # print(f'After conv1: {x.shape}')\n","        x = relu(self.spade2(x, seg) ) #b, 128, 30,50  \n","        x = self.conv2(x) #b, 128, 30, 50\n","\n","        if self.skip:\n","            x_skip = relu(self.spade_skip(x_skip, seg))\n","            x_skip = self.conv_skip(x_skip)\n","        # print(f'After spade1: {(x_skip + x).shape}')\n","        return x_skip + x\n","\n","\n","\n","class Generator(nn.Module):\n","    def __init__(self, args, inchannels): #---------_Remember inchannels\n","        super().__init__()\n","        self.linear = nn.Linear(args.gen_input_size, args.gen_hidden_size)\n","        self.fc = nn.Conv2d(inchannels, 128, kernel_size = (3,3), padding = 1)\n","        self.spade_resblk1 = SPADEResBlk(args, 128)\n","        self.spade_resblk2 = SPADEResBlk(args, 128)\n","        self.spade_resblk3 = SPADEResBlk(args, 64, skip=True)\n","        self.spade_resblk4 = SPADEResBlk(args, 32, skip=True)\n","        self.conv = nn.utils.spectral_norm(nn.Conv2d(32, 3, kernel_size=(3,3), padding=1))\n","        self.convTrans128 = nn.ConvTranspose2d(128, 128, kernel_size = 2, stride = 2)\n","        self.convTrans64 = nn.ConvTranspose2d(64, 64, kernel_size = 2, stride = 2)\n","        self.convTrans32 = nn.ConvTranspose2d(32, 32, kernel_size = 2, stride = 2)\n","\n","    \n","    def forward(self, seg):\n","        # x = self.linear(x)\n","        # print(f'After linear {x.shape}')\n","        # x = x.view(seg.size(0), -1, 15, 25) #change 4 4 such that -1 = 128 If change this also change hidden layer size with x*y\n","        # print(f'After view {x.shape}')\n","        #x.shape = 8,4,15,25\n","        m4 = F.interpolate(seg, scale_factor = 0.5, mode = \"bicubic\") #b, 4, 240, 400\n","        m3 = F.interpolate(m4, scale_factor = 0.5, mode = \"bicubic\") #b, 4, 120, 200\n","        m2 = F.interpolate(m3, scale_factor = 0.5, mode = \"bicubic\") #b, 4, 60, 100\n","        m1 = F.interpolate(m2, scale_factor = 0.5, mode = \"bicubic\") #b, 4, 30, 50 \n","\n","        # print(f'm1: {m1.shape}')\n","        x = self.fc(m1) #b, 128, 30, 50\n","        # print(f'fc: {x.shape}')\n","        x = self.spade_resblk1(x, m1) #b, 128, 30, 50\n","        #print(f'resblk1: {x.shape} type {type(x)}')\n","        x= self.convTrans128(x)\n","        #x = F.interpolate(x, scale_factor = 2, mode='bicubic') #b, 128, 60, 100\n","        #print(f'interpolate1: {x.shape}')\n","\n","        x = self.spade_resblk2(x, m2) #b, 128, 60, 100\n","        #print(f'resblk2: {x.shape}')\n","        x= self.convTrans128(x)\n","        #x = F.interpolate(x, scale_factor = 2, mode='bicubic')#b, 128, 120, 200\n","        #print(f'interpolate 2: {x.shape}')\n","\n","        x = self.spade_resblk3(x, m3)  #b, 64, 120,200\n","        #print(f'resblk3: {x.shape}')\n","        x= self.convTrans64(x)\n","\n","        #x = F.interpolate(x,scale_factor = 2, mode='bicubic')#b, 64, 240, 400 \n","       # print(f'interpolate3: {x.shape}')\n","        \n","        x = self.spade_resblk4(x, m4)  #b, 32, 240, 400\n","        # print(f'resblk4: {x.shape}')\n","        x= self.convTrans32(x)\n","\n","        #x = F.interpolate(x, scale_factor = 2, mode='bicubic')#b, 32, 480, 800\n","        # print(f'interpolate 4: {x.shape}')\n","\n","        x = F.tanh(self.conv(x)) #b, 3, 480, 800\n","        # print(f'tanh: {x.shape}')\n","        \n","        return x"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1679830889157,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"YuqjBJxDn7kw"},"outputs":[],"source":["\n","\n","def custom_model1(in_chan, out_chan):\n","    return nn.Sequential(\n","        spectral_norm(nn.Conv2d(in_chan, out_chan, kernel_size=(4,4), stride=2, padding=1)),\n","        nn.LeakyReLU(inplace=False)\n","    )\n","\n","def custom_model2(in_chan, out_chan, stride=2):\n","    return nn.Sequential(\n","        spectral_norm(nn.Conv2d(in_chan, out_chan, kernel_size=(4,4), stride=stride, padding=1)),\n","        nn.InstanceNorm2d(out_chan),\n","        nn.LeakyReLU(inplace=False)\n","    )\n","\n","class SPADEDiscriminator(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.layer1 = custom_model1(7, 64)  #here channel\n","        self.layer2 = custom_model2(64, 128)\n","        self.layer3 = custom_model2(128, 256)\n","        self.layer4 = custom_model2(256, 512, stride=1)\n","        self.inst_norm = nn.InstanceNorm2d(512)\n","        self.conv = spectral_norm(nn.Conv2d(512, 1, kernel_size=(4,4), padding=1))\n","\n","    def forward(self, img, seg):\n","        x = torch.cat((seg, img.detach()), dim=1)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = leaky_relu(self.inst_norm(x), inplace =False)\n","        x = self.conv(x)\n","        return x\n","\n","\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, inchannel):\n","        super().__init__()\n","        self.inchannel = inchannel\n","        self.layer1 = custom_model1(inchannel, 32) #Changed here our's 7 channel + 3 channel\n","        self.layer2 = custom_model2(32, 64)\n","        self.layer3 = custom_model2(64, 128)\n","        self.layer4 = custom_model2(128, 256)\n","        self.inst_norm = nn.InstanceNorm2d(256)\n","        self.conv = nn.utils.spectral_norm(nn.Conv2d(256, 1, kernel_size=(4,4)))\n","\n","    def forward(self, img, seg):\n","        x = torch.cat((img, seg), dim=1)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","        x = F.leaky_relu(self.inst_norm(x))\n","\n","        x = self.conv(x)\n","        return x.squeeze()"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1679830889157,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"0ZUIakgVn8Xd"},"outputs":[],"source":["class DownSampleConv(nn.Module):\n","\n","    def __init__(self, in_channels, out_channels, kernel=4, strides=2, padding=1, activation=True, batchnorm=True):\n","        \"\"\"\n","        Paper details:\n","        - C64-C128-C256-C512-C512-C512-C512-C512\n","        - All convolutions are 4Ã—4 spatial filters applied with stride 2\n","        - Convolutions in the encoder downsample by a factor of 2\n","        \"\"\"\n","        super().__init__()\n","        self.activation = activation\n","        self.batchnorm = batchnorm\n","\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel, strides, padding)\n","\n","        if batchnorm:\n","            self.bn = nn.BatchNorm2d(out_channels)\n","\n","        if activation:\n","            self.act = nn.LeakyReLU(0.2)\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        if self.batchnorm:\n","            x = self.bn(x)\n","        if self.activation:\n","            x = self.act(x)\n","        return x\n","\n","\n","class PatchGAN(nn.Module):\n","\n","    def __init__(self, input_channels):\n","        super().__init__()\n","        self.d1 = DownSampleConv(input_channels, 32, batchnorm=False)\n","        self.d2 = DownSampleConv(32, 64)\n","        self.d3 = DownSampleConv(64, 64)\n","        self.d4 = DownSampleConv(64, 64)\n","        self.final = nn.Conv2d(64, 1, kernel_size=1)\n","\n","    def forward(self, x, y):\n","        x = torch.cat([x, y], axis=1)\n","        x0 = self.d1(x)\n","        x1 = self.d2(x0)\n","        x2 = self.d3(x1)\n","        x3 = self.d4(x2)\n","        xn = self.final(x3)\n","        return xn\n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1679830889159,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"f0EXpvaZoKhn"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1679830889159,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"3up_apKH3kc0"},"outputs":[],"source":["\n","\n","class GANLoss(nn.Module):\n","    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n","                 tensor=torch.FloatTensor):\n","        super().__init__()\n","        self.real_label = target_real_label\n","        self.fake_label = target_fake_label\n","        self.real_label_var = None\n","        self.fake_label_var = None\n","        self.Tensor = tensor\n","        if use_lsgan:\n","            self.loss = nn.L1Loss()\n","        else:\n","            self.loss = nn.BCEWithLogitsLoss()\n","            \n","    def get_target_tensor(self, input, target_is_real):\n","        target_tensor = None\n","        if target_is_real:\n","            create_label = ((self.real_label_var is None) or\n","                            (self.real_label_var.numel() != input.numel()))\n","            if create_label:\n","                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n","                self.real_label_var = torch.tensor(real_tensor, requires_grad=False)\n","            target_tensor = self.real_label_var\n","        else:\n","            create_label = ((self.fake_label_var is None) or\n","                            (self.fake_label_var.numel() != input.numel()))\n","            if create_label:\n","                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n","                self.fake_label_var = torch.tensor(fake_tensor, requires_grad=False)\n","            \n","            target_tensor = self.fake_label_var\n","        return target_tensor\n","\n","    def __call__(self, input, target_is_real):        \n","        target_tensor = self.get_target_tensor(input, target_is_real)\n","\n","        return self.loss(input, target_tensor.to(device)) #here------>for loss GPU\n"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1679830889159,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"kB40pJlroMEW"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1679830889160,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"8aXcta8Ql5dc"},"outputs":[],"source":["def display_progress(cond, fake, real, figsize=(10,5)):\n","    cond = cond.detach().cpu().permute(1, 2, 0)\n","    fake = fake.detach().cpu().permute(1, 2, 0)\n","    real = real.detach().cpu().permute(1, 2, 0)\n","    \n","    fig, ax = plt.subplots(1, 3, figsize=figsize)\n","    # print(cond.shape)\n","    ax[0].imshow(cond[:,:,0:3])\n","    ax[2].imshow(fake)\n","    ax[1].imshow(real)\n","    plt.show()"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1679830889160,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"xuVDqG1noN4j"},"outputs":[],"source":["\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","else:\n","  device = torch.device('cpu')\n","    # raise Exception('GPU not available')\n","torch.backends.cudnn.benchmark = True\n","\n","gen = Generator(args,inchannels = CONFIG['IN_CHANNEL_GEN'])\n","dis = Discriminator(CONFIG['IN_CHANNEL_DIS'])\n","#dis = SPADEDiscriminator()\n","gen = gen.to(device)\n","dis = dis.to(device)\n","\n","gen.apply(weights_init)\n","dis.apply(weights_init)\n","\n","criterionG = GANLoss()    #L1Loss\n","criterionD = GANLoss(use_lsgan = False) #logitLoss \n","recon_loss = nn.L1Loss()\n","\n","optim_gen = torch.optim.Adam(gen.parameters(), lr=CONFIG['Lr_GEN'])\n","optim_dis = torch.optim.Adam(dis.parameters(), lr=CONFIG['Lr_DIS'])\n"]},{"cell_type":"code","execution_count":41,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1679830889161,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"MfV0vZjXkCxx"},"outputs":[],"source":["# dataset = GrassDataset(path)\n","# dataloader = DataLoader(dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\n","# print(len(dataloader))\n","# for i, (condition, real) in enumerate(dataloader):\n","#   print(condition)\n","#   print(real)\n","#   break"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1679830889161,"user":{"displayName":"ANJU CHHETRI","userId":"06841725651527849321"},"user_tz":-345},"id":"VqV_WviY2np9"},"outputs":[],"source":["from torchvision.utils import make_grid, save_image"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1GpQxJiFhkB2DAQRLA-tIV45k0KJ-IKhC"},"id":"d4EJRsosoP-Y","outputId":"4d2d089c-ee19-4809-f8d2-7c089838d251"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["img_lists = []\n","G_losses = []\n","D_losses = []\n","epochs = 1\n","iters = 0\n","recon_var = 100\n","import time\n","\n","path = CONFIG['PATH_DATA']\n","dataset = GrassDataset(path)\n","dataloader = DataLoader(dataset, batch_size=CONFIG['BATCH_SIZE'], shuffle=True)\n","path_save = CONFIG['RESULT_PATH']\n","for epoch in tqdm(range(CONFIG['MAX_EPOCH'])):\n","  start = time.time()\n","\n","  print(f'Epoch: {epoch+1}')\n","  for i, (condition, real) in enumerate(dataloader):\n","    if(condition.size(0) != CONFIG['BATCH_SIZE']):  #If dataset not in multiple of 8\n","      break\n","    con = condition.to(device)\n","    real = real.to(device)\n","\n","    fake_img = gen(con)  \n","    if i%2==0:\n","    #Discriminator\n","      pred_real = dis(real, con)\n","      loss_D_real = criterionD(pred_real, True)\n","\n","      #Fake Detection\n","      pred_fake = dis(fake_img.detach(), con) \n","      loss_D_fake = criterionD(pred_fake, False)\n","\n","      #back for discriminator\n","      optim_dis.zero_grad()\n","      loss_D = loss_D_fake + loss_D_real*0.5 #culprit-------> loss_D_fake\n","      loss_D.backward(retain_graph= True)\n","      optim_dis.step()\n","\n","    #Generator\n","    optim_gen.zero_grad()\n","    pred_fake = dis(fake_img, con) #Shape\n","    loss_G_d = criterionG(pred_fake, True)\n","    loss_G_recon = recon_loss(fake_img, real)\n","    loss_G = loss_G_d + (recon_var*loss_G_recon)\n","    loss_G.backward()\n","\n","    optim_gen.step()\n","\n","    G_losses.append(loss_G.detach().cpu())\n","    D_losses.append(loss_D.detach().cpu())\n","    \n","    if i%20 == 0:\n","      print(\"Iteration {}/{} started\".format(i+1, len(dataloader)))\n","      fake_img = gen(con).detach()\n","      display_progress(con[0,:,:,:],fake_img[0,:,:,:], real[0,:,:,:] )\n","      print(f'loss_D: {loss_D.detach()} loss_g: {loss_G.detach()}')\n","      print(time.time()-start)\n","      start = time.time()\n","\n","      path_e = path_save + str(epoch) + \"_\" + str(i) + \".png\"\n","      save_image(fake_img[0], path_e)\n","  if epoch%5 == 0:\n","    with torch.no_grad():\n","      img_lists.append(fake_img.detach().cpu().numpy())      \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTOE_Jjl1ZkU"},"outputs":[],"source":["#torch.cuda.empty_cache()\n","import torch\n","torch.cuda.memory_summary(device=None, abbreviated=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zSdAeeKeV-yW"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","x = torch.randn(8,7,30,50)\n","mat = nn.ConvTranspose2d(x.size(1), x.size(1), 2, stride = 2)\n","x = mat(x)\n","print(x.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uxerKMhYyUov"},"outputs":[],"source":["total = sum(\n","    \n","    params.numel() for params in gen.parameters() \n",")\n","print(total)"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1Xkn0JOM9bPxRxENDR5PSiJNZRLBKmDZg","authorship_tag":"ABX9TyPTedFQEYUqMIAg2vrB0pYE"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}